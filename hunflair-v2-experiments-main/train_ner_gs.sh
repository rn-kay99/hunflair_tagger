#!/usr/bin/env bash

# # LSTM
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_lstm --data_path /home/tmp/hunflair --batch_size 32 > ./_output/gene_lstm 
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_lstm_ablation --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/gene_lstm_ablation 
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type disease --path /home/tmp/hunflair/disease_lstm_ablation --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_exclude biored > ./_output/disease_lstm_ablation 

# # Learning rate hyperparameter tuning
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_transformers_lr_1e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base"  --train_with_test --learning_rate 1.0e-5 > ./_output/gene_transformers_lr_1e-5
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_transformers_lr_2e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base"  --train_with_test --learning_rate 2.0e-5 > ./_output/gene_transformers_lr_2e-5
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_transformers_lr_3e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base"  --train_with_test --learning_rate 3.0e-5 > ./_output/gene_transformers_lr_3e-5

# # Cell line model
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type cell_line --path /home/tmp/hunflair/cell_line_transformers_lr_2e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_lr_2e-5_sanity_check --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5_sanity_check
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_lr_2e-5_sanity_check --data_path /home/tmp/hunflair --batch_size 12 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5_sanity_check_2
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_lr_2e-5_sanity_check_3 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5_sanity_check_3
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_lr_2e-5_batch_size_8 --data_path /home/tmp/hunflair --batch_size 8 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5_batch_size_8
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_lr_2e-5_batch_size_16 --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/cell_line_transformers_lr_2e-5_batch_size_16

# # Disease model
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type disease --path /home/tmp/hunflair/disease_transformers_lr_2e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/disease_transformers_lr_2e-5

# # Chemical model
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type chemical --path /home/tmp/hunflair/chemical_transformers_lr_2e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/chemical_transformers_lr_2e-5

# # Species model
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type species --path /home/tmp/hunflair/species_transformers_lr_2e-5 --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/species_transformers_lr_2e-5
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type species --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/species_transformers_lr_2e-5_batch_size_12 --data_path /home/tmp/hunflair --batch_size 12 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 > ./_output/species_transformers_lr_2e-5_batch_size_12

# # Hunflair v1 compability check/ablation study by ignoring new datasets
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_transformers_lr_2e-5_ablation --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/gene_transformers_lr_2e-5_ablation

# # Multi-task learning
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type all --path /home/tmp/hunflair/multi_task_learning/biored --data_path /home/tmp/hunflair/multi_task_learning_2 --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --train_corpora_include biored > ./_output/experiments/multi_task_learning_biored_2
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type all --path /home/tmp/hunflair/multi_task_learning/all_2 --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning > ./_output/experiments/multi_task_learning_all_2
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type mtl --path /home/tmp/hunflair/multi_task_learning/mtl --data_path /home/tmp/hunflair/multi_task_learning --batch_size 12 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning > ./_output/experiments/multi_task_learning_mtl
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type mtl --path /home/tmp/hunflair/multi_task_learning/mtl --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --train_corpora_include biored > ./_output/experiments/multi_task_learning_mtl_biored
# # Multi-task learning with AIONER
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type mtl --path /home/tmp/hunflair/aioner --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --aioner > ./_output/experiments/aioner
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type mtl --path /home/tmp/hunflair/aioner_adapted --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --aioner --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/aioner_adapted
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type mtl --path /home/tmp/hunflair/aioner_adapted_2 --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --aioner --aioner_remove_duplicates --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/aioner_adapted_2
# # Multi-task learning with AIO
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type all --path /home/tmp/hunflair/aio --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/aio

# # Multi-task learning with AIO (all datasets)
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type all --path /home/tmp/hunflair/aio_all_datasets --data_path /home/tmp/hunflair/multi_task_learning --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --multi_task_learning > ./_output/experiments/ablations/aio_all_datasets

# # LSTM with all new datasets (no BC5CDR)
# # Disease is most important to test => no access to BC5CDR
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type disease --path /home/tmp/hunflair/disease_lstm_all_datasets --data_path /home/tmp/hunflair --batch_size 32 > ./_output/experiments/ablations/disease_lstm_all_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_lstm_all_datasets --data_path /home/tmp/hunflair --batch_size 32 > ./_output/experiments/ablations/gene_lstm_all_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type chemical --path /home/tmp/hunflair/chemical_lstm_all_datasets --data_path /home/tmp/hunflair --batch_size 32 > ./_output/experiments/ablations/chemical_lstm_all_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type cell_line --path /home/tmp/hunflair/cell_line_lstm_all_datasets --data_path /home/tmp/hunflair --batch_size 32 > ./_output/experiments/ablations/cell_line_lstm_all_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type species --path /home/tmp/hunflair/species_lstm_all_datasets --data_path /home/tmp/hunflair --batch_size 32 > ./_output/experiments/ablations/species_lstm_all_datasets

# BioLinkBERT with old datasets
# With BC5CDR
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type disease --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/disease_transformers_old_datasets_bc5cdr --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --bc5cdr_train --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/disease_transformers_old_datasets_bc5cdr
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type chemical --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/chemical_transformers_old_datasets_bc5cdr --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --bc5cdr_train --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/chemical_transformers_old_datasets_bc5cdr
# Without BC5CDR
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type cell_line --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/cell_line_transformers_old_datasets --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus --seed 2 > ./_output/experiments/ablations/tmp
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type disease --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/disease_transformers_old_datasets --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/disease_transformers_old_datasets
# CUDA_VISIBLE_DEVICES=1 python train_ner_gs_model.py --type chemical --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/chemical_transformers_old_datasets --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/chemical_transformers_old_datasets
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type gene --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/gene_transformers_old_datasets --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/gene_transformers_old_datasets
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type species --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/species_transformers_old_datasets --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_exclude nlm_gene drugprot biored cpi bionlp_st_2013_pc bionlp_st_2013_ge bionlp_st_2011_ge bionlp_st_2011_id bionlp_st_2011_rel bionlp_2011_epi progene gnormplus nlm_chem bionlp_st_2019_bb seth_corpus > ./_output/experiments/ablations/species_transformers_old_datasets

# LSTM with the nine high-quality datasets
# Disease is most important to test => no access to BC5CDR
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type disease --path /home/tmp/hunflair/disease_lstm_aio_datasets --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/disease_lstm_aio_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_lstm_aio_datasets --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/gene_lstm_aio_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type chemical --path /home/tmp/hunflair/chemical_lstm_aio_datasets --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/chemical_lstm_aio_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type cell_line --path /home/tmp/hunflair/cell_line_lstm_aio_datasets --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/cell_line_lstm_aio_datasets 
# CUDA_VISIBLE_DEVICES=2 python train_ner_gs_model.py --type species --path /home/tmp/hunflair/species_lstm_aio_datasets --data_path /home/tmp/hunflair --batch_size 32 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/species_lstm_aio_datasets

# BioLinkBERT with the nine high-quality datasets
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type cell_line --path /home/tmp/hunflair/cell_line_transformers_aio_datasets --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/cell_line_transformers_aio_datasets
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type disease --path /home/tmp/hunflair/disease_transformers_aio_datasets --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/disease_transformers_aio_datasets
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type chemical --path /home/tmp/hunflair/chemical_transformers_aio_datasets --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/chemical_transformers_aio_datasets
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type gene --path /home/tmp/hunflair/gene_transformers_aio_datasets --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/gene_transformers_aio_datasets
# CUDA_VISIBLE_DEVICES=3 python train_ner_gs_model.py --type species --path /home/tmp/hunflair/species_transformers_aio_datasets --data_path /home/tmp/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora_include biored nlm_gene gnormplus scai nlm_chem linneaus s800 ncbi > ./_output/experiments/ablations/species_transformers_aio_datasets

# Reproducibility test
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type gene --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/reproducibility_test --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair/reproducibility_test --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --train_with_test --learning_rate 2.0e-5 --train_corpora biored --test_corpora > ./_output/reproducibility_test

# In-corpus training
# BC5CDR AIO
CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type all --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/in_corpus_training_bc5cdr_aio --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "/glusterfs/dfs-gfs-dist/wangxida/hunflair/aio_seed_1/all" --learning_rate 2.0e-5 --train_corpora cdr --test_corpora > ./_output/in_corpus_training
# BC5CDR Normal
# CUDA_VISIBLE_DEVICES=0 python train_ner_gs_model.py --type gene --path /glusterfs/dfs-gfs-dist/wangxida/hunflair/in_corpus_training --data_path /glusterfs/dfs-gfs-dist/wangxida/hunflair --batch_size 16 --transformer_word_embedding "michiyasunaga/BioLinkBERT-base" --learning_rate 2.0e-5 --train_corpora cdr --test_corpora > ./_output/in_corpus_training
